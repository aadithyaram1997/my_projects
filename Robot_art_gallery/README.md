# ğŸ¨ğŸ¤– Robot Art Gallery (ROS2) â€” TurtleBot Navigation + Artwork + AprilTag Detection

Course project for **ARAMS (Advanced Robotics and Autonomous Mobile Systems)** at **FH Aachen**.

This project runs a TurtleBot3 in a simulated art gallery, performs SLAM + waypoint navigation, captures wall images ğŸ“¸, detects artworks ğŸ–¼ï¸, and associates them with AprilTag IDs ğŸ·ï¸.

---

## ğŸ–¼ï¸ Screenshots

<p><b>Initialisation (SLAM / Nav2 bringup)</b></p>
<img src="Images/Initialisation.jpg" width="550" />

<p><b>Navigation with image detection</b></p>
<img src="Images/Navigation.jpg" width="550" />

<p><b>Output at the end</b></p>
<img src="Images/Output.jpg" width="550" />

---


## ğŸ“ Repository structure
- `my_robot_slam/` â€” ROS2 package (launch files for SLAM + execution)
- `Documentation/` â€” Project report (PDF) ğŸ“„
- `Project_video/` â€” Demo video(s) ğŸ¥
- `README.md` â€” This file ğŸ§¾

---

## âœ… Requirements
- Ubuntu + ROS2 Foxy installed ğŸ§
- colcon build tools available ğŸ§°
- Internet access to clone dependencies ğŸŒ

---

## ğŸ› ï¸ Setup (from scratch)

### 1) Install ROS / Ubuntu dependencies ğŸ“¦
```bash
sudo apt update
sudo apt install ros-foxy-gazebo* ros-foxy-tf-transformations ros-foxy-nav2* -y
```
### 2) Install Python dependencies ğŸ

```bash

sudo pip3 install transforms3d
pip3 install openvino opencv-python
```
### 3) Create workspace + clone repositories ğŸ“¥

```bash

mkdir -p ~/ros_ws/src
cd ~/ros_ws/src

# AprilTag repository
git clone https://github.com/Tinker-Twins/AprilTag

# Art gallery repository (course environment)
git clone https://git.fh-aachen.de/mascor-public/arams/art_gallery -b 3at5

# Project repository (implementation)
git clone https://git.fh-aachen.de/vh5465s/arams_project_2022.git

```
### 4) Build ğŸ”¨
```bash
cd ~/ros_ws
colcon build --symlink-install

```
### â–¶ï¸ Run (3 terminals) ğŸ–¥ï¸ğŸ–¥ï¸ğŸ–¥ï¸
Open three terminals and run the following:

### Terminal 1 â€” Start Gazebo simulation ğŸŒ

```bash
cd ~/ros_ws
source install/setup.bash
ros2 launch tb3_gazebo arams.launch.py
```

### Terminal 2 â€” Start SLAM initialization ğŸ—ºï¸

```bash
cd ~/ros_ws
source install/setup.bash
ros2 launch my_robot_slam initiate.launch.py
```

### Terminal 3 â€” Start main execution (navigation + capture + detection) ğŸš¶â€â™‚ï¸ğŸ“¸ğŸ”

```bash
cd ~/ros_ws
source install/setup.bash
ros2 launch my_robot_slam begin.launch.py
```

### ğŸ§¾ Output
- The robot navigates to defined waypoints ğŸ“, faces walls ğŸ§­, captures images ğŸ“¸, and runs detection ğŸ”.

- The final output displays detected artworks ğŸ–¼ï¸ together with associated AprilTag IDs ğŸ·ï¸.

### âš ï¸ Notes/ Known issues

- If real-time detection is heavy on the laptop ğŸ’», it can be more stable to capture wall images first and run detection after.

- If the robot collides with a wall ğŸ’¥, restart the simulation and rerun the launch sequence.

